

> 1. producer 端: 宏观上看保证数据的可靠安全性，肯定是依据分区数做好数据备份，设立副本数。
> 2. broker 端:
topic 设置多分区，分区自适应所在机器，为了让各分区均匀分布在所在的 broker 中，分 区数要大于 broker 数。
分区是 kafka 进行并行读写的单位，是提升 kafka 速度的关键。
> 3. Consumer 端
consumer 端丢失消息的情形比较简单:如果在消息处理完成前就提交了 offset，那么就有可能造成数据的丢失。由于 Kafka consumer 默认是自动提交位移的，所以在后台提交位 移前一定要保证消息被正常处理了，因此不建议采用很重的处理逻辑，如果处理耗时很长， 则建议把逻辑放到另一个线程中去做。为了避免数据丢失，现给出两点建议: enable.auto.commit=false 关闭自动提交位移
                                                在消息被完整处理之后再手动提交位移
